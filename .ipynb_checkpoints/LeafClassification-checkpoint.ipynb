{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leaf Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import KFold,GridSearchCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import neighbors\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "from scipy.stats.stats import pearsonr   \n",
    "\n",
    "train = pd.read_csv('./input/train.csv')\n",
    "test = pd.read_csv('./input/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Preparation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "classLabel = label_encoder.fit(train.species)\n",
    "labels = label_encoder.fit_transform(train.species)\n",
    "classes = list(classLabel.classes_)                    \n",
    "test_ids = test.id\n",
    "\n",
    "train = train.drop(['species', 'id'], axis=1)\n",
    "test = test.drop(['id'], axis=1)\n",
    "\n",
    "scaler = StandardScaler().fit(train)\n",
    "train = scaler.transform(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#K-fold with 5  \n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48686868686868684"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# naive bayse with K-fold cross validation\n",
    "nb = GaussianNB()\n",
    "#standardization\n",
    "#scaler = StandardScaler().fit(train)\n",
    "#train = scaler.transform(train)\n",
    "naiveBayseScore = list()\n",
    "for train_index, test_index in kfold.split(train):\n",
    "    X_train, X_test = train[train_index], train[test_index]\n",
    "    y_train, y_test = labels[train_index], labels[test_index]\n",
    "    naiveBayse = nb.fit(X_train,y_train)\n",
    "    naiveBayseScore.append(naiveBayse.score(X_test, y_test))\n",
    "nb_validation = naiveBayseScore\n",
    "\n",
    "#nb_validation=[nb.fit(train[train_index], labels[train_index]).score(train[test_index], labels[test_index]).mean() \\\n",
    "#              for train_index, test_index in kfold.split(train)]\n",
    "np.mean(nb_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:455: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.97171717171717165"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#linear DiscriminatAnalysis\n",
    "ld = LinearDiscriminantAnalysis(priors=None)\n",
    "linearDiscScore = list()\n",
    "\n",
    "for train_index, test_index in kfold.split(train):\n",
    "    X_train, X_test = train[train_index], train[test_index]\n",
    "    y_train, y_test = labels[train_index], labels[test_index]\n",
    "    linearDisc = ld.fit(X_train,y_train)\n",
    "    linearDiscScore.append(linearDisc.score(X_test, y_test))\n",
    "ld_validation = linearDiscScore\n",
    "\n",
    "np.mean(ld_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96262626262626261"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#KNearestNeighbours\n",
    "knn = neighbors.KNeighborsClassifier(algorithm='ball_tree',weights= 'distance')\n",
    "kNNScore = list()\n",
    "for train_index, test_index in kfold.split(train):\n",
    "    X_train, X_test = train[train_index], train[test_index]\n",
    "    y_train, y_test = labels[train_index], labels[test_index]\n",
    "    KnnCl = knn.fit(X_train,y_train)\n",
    "    kNNScore.append(KnnCl.score(X_test, y_test))\n",
    "knn_validation = kNNScore\n",
    "\n",
    "np.mean(knn_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98181818181818203"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "\n",
    "logreg = LogisticRegression(solver='lbfgs',multi_class='multinomial')\n",
    "logregScore = list()\n",
    "\n",
    "for train_index, test_index in kfold.split(train):\n",
    "    X_train, X_test = train[train_index], train[test_index]\n",
    "    y_train, y_test = labels[train_index], labels[test_index]\n",
    "    LogReg = logreg.fit(X_train,y_train)\n",
    "    logregScore.append(LogReg.score(X_test, y_test))\n",
    "ls_validation = logregScore\n",
    "\n",
    "#gs_validation=[gs.fit(train[train_index], labels[train_index]).score(train[test_index], labels[test_index]).mean() \\\n",
    "#              for train_index, test_index in kfold.split(train)]\n",
    "np.mean(ls_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98383838383838373"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Logistic Regression and a GridSearch\n",
    "\n",
    "params = {'C':[100, 1000], 'tol': [0.001, 0.0001]}\n",
    "lr = LogisticRegression(solver='lbfgs', multi_class='multinomial')\n",
    "gs = GridSearchCV(lr, params, scoring=None, refit='True', cv=3) \n",
    "gridSearchScore = list()\n",
    "\n",
    "for train_index, test_index in kfold.split(train):\n",
    "    X_train, X_test = train[train_index], train[test_index]\n",
    "    y_train, y_test = labels[train_index], labels[test_index]\n",
    "    GridSearch = gs.fit(X_train,y_train)\n",
    "    gridSearchScore.append(GridSearch.score(X_test, y_test))\n",
    "gs_validation = gridSearchScore\n",
    "\n",
    "#gs_validation=[gs.fit(train[train_index], labels[train_index]).score(train[test_index], labels[test_index]).mean() \\\n",
    "#              for train_index, test_index in kfold.split(train)]\n",
    "\n",
    "np.mean(gs_validation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#random forest\n",
    "rf = RandomForestClassifier(n_estimators=500)\n",
    "#random forest\n",
    "randomForestScore = list()\n",
    "\n",
    "for train_index, test_index in kfold.split(train):\n",
    "    X_train, X_test = train[train_index], train[test_index]\n",
    "    y_train, y_test = labels[train_index], labels[test_index]\n",
    "    #fit\n",
    "    randomForest = rf.fit(X_train,y_train)\n",
    "    randomForestScore.append(randomForest.score(X_test, y_test))\n",
    "\n",
    "rf_validation = randomForestScore\n",
    "\n",
    "#rf_validation=[rf.fit(train[train_index], labels[train_index]).score(train[test_index], labels[test_index]).mean() \\\n",
    "#              for train_index, test_index in kfold.split(train)]\n",
    "np.mean(rf_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#random forest\n",
    "etcl = ExtraTreesClassifier(n_estimators=500, random_state=0)\n",
    "ExtraTreeScore = list()\n",
    "\n",
    "for train_index, test_index in kfold.split(train):\n",
    "    X_train, X_test = train[train_index], train[test_index]\n",
    "    y_train, y_test = labels[train_index], labels[test_index]\n",
    "    #fit\n",
    "    ExtraTree = etcl.fit(X_train,y_train)\n",
    "    ExtraTreeScore.append(ExtraTree.score(X_test, y_test))\n",
    "\n",
    "etcl_validation = ExtraTreeScore\n",
    "\n",
    "#rf_validation=[rf.fit(train[train_index], labels[train_index]).score(train[test_index], labels[test_index]).mean() \\\n",
    "#              for train_index, test_index in kfold.split(train)]\n",
    "np.mean(etcl_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "importances = rf.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "imp_std = np.std([est.feature_importances_ for est in rf.estimators_], axis=0)\n",
    "fig = plt.figure(figsize=(12, 4))\n",
    "\n",
    "gs1 = gridspec.GridSpec(1, 2,height_ratios=[1])\n",
    "\n",
    "ax1, ax2 = fig.add_subplot(gs1[0]), fig.add_subplot(gs1[1])\n",
    "\n",
    "ax1.margins(0.05), ax2.margins(0.05) \n",
    "\n",
    "ax1.bar(range(10), importances[indices][:10], \\\n",
    "       color=\"#6480e5\", yerr=imp_std[indices][:10], ecolor='#31427e', align=\"center\")\n",
    "\n",
    "ax2.bar(range(10), importances[indices][-10:], \\\n",
    "       color=\"#e56464\", yerr=imp_std[indices][-10:], ecolor='#7e3131', align=\"center\")\n",
    "\n",
    "ax1.set_xticks(range(10)), ax2.set_xticks(range(10))\n",
    "\n",
    "ax1.set_xticklabels(indices[:10]), ax2.set_xticklabels(indices[-10:])\n",
    "\n",
    "ax1.set_xlim([-1, 10]), ax2.set_xlim([-1, 10])\n",
    "ax1.set_ylim([0, 0.035]), ax2.set_ylim([0, 0.035])\n",
    "\n",
    "ax1.set_xlabel('Feature numbers'), ax2.set_xlabel('Feature numbers')\n",
    "ax1.set_ylabel('Random Forest Normalized Importance') \n",
    "ax2.set_ylabel('Random Forest Normalized Importance')\n",
    "\n",
    "ax1.set_title('First 10 Important Features'), ax2.set_title('Last 10 Important Features')\n",
    "gs1.tight_layout(fig)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#correlation analysis (TBD)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#feature selection exploration\n",
    "svc = SVC(kernel=\"linear\")\n",
    "ld = LinearDiscriminantAnalysis();\n",
    "\n",
    "featureSelector = RFECV(estimator=svc, step = 1, cv=5, scoring='accuracy')\n",
    "\n",
    "rfecv = featureSelector.fit(train, labels)\n",
    "train_rfecv = rfecv.transform(train) \n",
    "\n",
    "print(\"Optimal number of features : %d\" % featureSelector.n_features_)\n",
    "\n",
    "plt.figure()\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.ylabel(\"Cross validation score (nb of correct classifications)\")\n",
    "plt.plot(range(1, len(featureSelector.grid_scores_) + 1), featureSelector.grid_scores_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#selection optimal n number of feature \n",
    "svc = SVC(kernel=\"linear\")\n",
    "rfe = RFE(estimator=svc, n_features_to_select=25, step=1)\n",
    "train_rfe = rfe.fit_transform(train, labels)\n",
    "\n",
    "train_rfe[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#after RFE\n",
    "naiveBayseScore = list()\n",
    "for train_index, test_index in kfold.split(train):\n",
    "    X_train, X_test = train_rfecv[train_index], train_rfecv[test_index]\n",
    "    y_train, y_test = labels[train_index], labels[test_index]\n",
    "    #fit\n",
    "    naiveBayse = nb.fit(X_train,y_train)\n",
    "    naiveBayseScore.append(naiveBayse.score(X_test, y_test))\n",
    "    \n",
    "nb_validation = naiveBayseScore\n",
    "\n",
    "np.mean(nb_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Priciple Component Analysis\n",
    "pca = PCA(n_components = 'mle', svd_solver = 'full',iterated_power='auto')\n",
    "pca_fit = pca.fit(train)\n",
    "train_pca=pca_fit.transform(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.90909090909090895"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#After PCA\n",
    "nb_pca = GaussianNB()\n",
    "naiveBayseScore = list()\n",
    "for train_index, test_index in kfold.split(train_pca):\n",
    "    X_train, X_test = train_pca[train_index], train_pca[test_index]\n",
    "    y_train, y_test = labels[train_index], labels[test_index]\n",
    "    naiveBayse = nb_pca.fit(X_train,y_train)\n",
    "    naiveBayseScore.append(naiveBayse.score(X_test, y_test))\n",
    "    \n",
    "nb_validation = naiveBayseScore\n",
    "np.mean(nb_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:455: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.97171717171717165"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#After PCA\n",
    "#linear DiscriminatAnalysis\n",
    "#shrinkage='auto',\n",
    "ld_pca = LinearDiscriminantAnalysis(solver='lsqr')\n",
    "linearDiscScore = list()\n",
    "\n",
    "for train_index, test_index in kfold.split(train_pca):\n",
    "    X_train, X_test = train_pca[train_index], train_pca[test_index]\n",
    "    y_train, y_test = labels[train_index], labels[test_index]\n",
    "    #fit\n",
    "    linearDisc = ld_pca.fit(X_train,y_train)\n",
    "    linearDiscScore.append(linearDisc.score(X_test, y_test))\n",
    "\n",
    "ld_validation = linearDiscScore\n",
    "\n",
    "np.mean(ld_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96262626262626261"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#After PCA\n",
    "#KNearestNeighbours\n",
    "knn_pca = neighbors.KNeighborsClassifier(algorithm='ball_tree',weights= 'distance')\n",
    "kNNScore = list()\n",
    "for train_index, test_index in kfold.split(train_pca):\n",
    "    X_train, X_test = train_pca[train_index], train_pca[test_index]\n",
    "    y_train, y_test = labels[train_index], labels[test_index]\n",
    "    KnnCl = knn_pca.fit(X_train,y_train)\n",
    "    kNNScore.append(KnnCl.score(X_test, y_test))\n",
    "    \n",
    "knn_validation = kNNScore\n",
    "\n",
    "np.mean(knn_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98383838383838373"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#After PCA\n",
    "#Logistic Regression and a GridSearch\n",
    "params = {'C':[100, 1000], 'tol': [0.001, 0.0001]}\n",
    "lr_pca = LogisticRegression(solver='lbfgs', multi_class='multinomial')\n",
    "gs_pca = GridSearchCV(lr_pca, params, scoring=None, refit='True', cv=3) \n",
    "gridSearchScore = list()\n",
    "\n",
    "for train_index, test_index in kfold.split(train_pca):\n",
    "    X_train, X_test = train_pca[train_index], train_pca[test_index]\n",
    "    y_train, y_test = labels[train_index], labels[test_index]\n",
    "    GridSearch = gs_pca.fit(X_train,y_train)\n",
    "    gridSearchScore.append(GridSearch.score(X_test, y_test))\n",
    "gs_validation = gridSearchScore\n",
    "\n",
    "np.mean(gs_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97575757575757582"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#After PCA\n",
    "#random forest\n",
    "etcl_pca = ExtraTreesClassifier(n_estimators=500, random_state=0)\n",
    "ExtraTreeScore = list()\n",
    "\n",
    "for train_index, test_index in kfold.split(train_pca):\n",
    "    X_train, X_test = train_pca[train_index], train_pca[test_index]\n",
    "    y_train, y_test = labels[train_index], labels[test_index]\n",
    "    #fit\n",
    "    ExtraTree = etcl_pca.fit(X_train,y_train)\n",
    "    ExtraTreeScore.append(ExtraTree.score(X_test, y_test))\n",
    "\n",
    "etcl_validation = ExtraTreeScore\n",
    "\n",
    "np.mean(etcl_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#bagging esemble the classifiers\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "#('nb_pca',nb_pca), ('ld_pca', ld_pca), ('knn_pca',knn_pca),\n",
    "eclf1 = VotingClassifier(estimators=[('nb_pca',nb_pca), ('knn_pca',knn_pca), ('gs_pca', gs_pca), \n",
    "                                     ('etcl_pca',etcl_pca)],\n",
    "                         voting='soft')\n",
    "VotingClassifierScore = list()\n",
    "for train_index, test_index in kfold.split(train_pca):\n",
    "    X_train, X_test = train_pca[train_index], train_pca[test_index]\n",
    "    y_train, y_test = labels[train_index], labels[test_index]\n",
    "    #fit\n",
    "    VotingClass = eclf1.fit(X_train,y_train)\n",
    "    VotingClassifierScore.append(VotingClass.score(X_test, y_test))\n",
    "\n",
    "np.mean(VotingClassifierScore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = scaler.transform(test)\n",
    "test_pca=pca_fit.transform(test)\n",
    "test_predictions = eclf1.predict_proba(test_pca)\n",
    "\n",
    "log_cols=[\"Classifier\", \"Accuracy\", \"Log Loss\"]\n",
    "log = pd.DataFrame(columns=log_cols)\n",
    "\n",
    "test_predictions = eclf1.predict(test)\n",
    "\n",
    "acc = accuracy_score(, test_predictions)\n",
    "\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished writing submission\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Acer_Capillipes</th>\n",
       "      <th>Acer_Circinatum</th>\n",
       "      <th>Acer_Mono</th>\n",
       "      <th>Acer_Opalus</th>\n",
       "      <th>Acer_Palmatum</th>\n",
       "      <th>Acer_Pictum</th>\n",
       "      <th>Acer_Platanoids</th>\n",
       "      <th>Acer_Rubrum</th>\n",
       "      <th>Acer_Rufinerve</th>\n",
       "      <th>Acer_Saccharinum</th>\n",
       "      <th>...</th>\n",
       "      <th>Salix_Fragilis</th>\n",
       "      <th>Salix_Intergra</th>\n",
       "      <th>Sorbus_Aria</th>\n",
       "      <th>Tilia_Oliveri</th>\n",
       "      <th>Tilia_Platyphyllos</th>\n",
       "      <th>Tilia_Tomentosa</th>\n",
       "      <th>Ulmus_Bergmanniana</th>\n",
       "      <th>Viburnum_Tinus</th>\n",
       "      <th>Viburnum_x_Rhytidophylloides</th>\n",
       "      <th>Zelkova_Serrata</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1576</th>\n",
       "      <td>8.570116e-07</td>\n",
       "      <td>9.998349e-01</td>\n",
       "      <td>1.491306e-07</td>\n",
       "      <td>2.367666e-08</td>\n",
       "      <td>8.240294e-05</td>\n",
       "      <td>7.842066e-08</td>\n",
       "      <td>3.390336e-09</td>\n",
       "      <td>1.839186e-06</td>\n",
       "      <td>5.145595e-06</td>\n",
       "      <td>9.248885e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>3.526926e-08</td>\n",
       "      <td>7.638954e-09</td>\n",
       "      <td>2.176534e-08</td>\n",
       "      <td>1.856065e-09</td>\n",
       "      <td>8.649973e-11</td>\n",
       "      <td>2.058003e-09</td>\n",
       "      <td>1.124400e-06</td>\n",
       "      <td>1.499914e-11</td>\n",
       "      <td>2.453847e-09</td>\n",
       "      <td>2.271927e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1577</th>\n",
       "      <td>2.488508e-07</td>\n",
       "      <td>9.220734e-08</td>\n",
       "      <td>1.271193e-09</td>\n",
       "      <td>1.042362e-06</td>\n",
       "      <td>9.857609e-09</td>\n",
       "      <td>4.736718e-10</td>\n",
       "      <td>2.317026e-08</td>\n",
       "      <td>1.060710e-05</td>\n",
       "      <td>8.001536e-05</td>\n",
       "      <td>8.654126e-09</td>\n",
       "      <td>...</td>\n",
       "      <td>1.390747e-08</td>\n",
       "      <td>6.374147e-09</td>\n",
       "      <td>4.393712e-06</td>\n",
       "      <td>8.712163e-10</td>\n",
       "      <td>1.003759e-05</td>\n",
       "      <td>1.025632e-05</td>\n",
       "      <td>1.602850e-07</td>\n",
       "      <td>2.873007e-11</td>\n",
       "      <td>2.523514e-09</td>\n",
       "      <td>2.382522e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1579</th>\n",
       "      <td>4.198415e-08</td>\n",
       "      <td>8.418455e-09</td>\n",
       "      <td>2.161047e-09</td>\n",
       "      <td>7.980462e-11</td>\n",
       "      <td>9.189209e-08</td>\n",
       "      <td>2.276649e-07</td>\n",
       "      <td>7.560791e-11</td>\n",
       "      <td>1.875409e-08</td>\n",
       "      <td>1.017468e-09</td>\n",
       "      <td>5.781226e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>7.700392e-13</td>\n",
       "      <td>3.637695e-12</td>\n",
       "      <td>8.703355e-09</td>\n",
       "      <td>3.443338e-10</td>\n",
       "      <td>2.509468e-09</td>\n",
       "      <td>1.865638e-14</td>\n",
       "      <td>2.058288e-12</td>\n",
       "      <td>1.944001e-10</td>\n",
       "      <td>2.157379e-09</td>\n",
       "      <td>1.884388e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1580</th>\n",
       "      <td>3.757027e-10</td>\n",
       "      <td>1.785899e-10</td>\n",
       "      <td>9.808644e-09</td>\n",
       "      <td>5.898435e-09</td>\n",
       "      <td>2.391792e-09</td>\n",
       "      <td>1.155581e-10</td>\n",
       "      <td>2.127765e-08</td>\n",
       "      <td>3.995165e-08</td>\n",
       "      <td>1.677714e-11</td>\n",
       "      <td>9.435058e-13</td>\n",
       "      <td>...</td>\n",
       "      <td>2.021303e-08</td>\n",
       "      <td>1.709390e-07</td>\n",
       "      <td>4.398426e-12</td>\n",
       "      <td>8.780395e-08</td>\n",
       "      <td>2.148123e-13</td>\n",
       "      <td>7.722929e-09</td>\n",
       "      <td>4.900621e-11</td>\n",
       "      <td>2.568975e-10</td>\n",
       "      <td>5.571697e-13</td>\n",
       "      <td>1.249406e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1583</th>\n",
       "      <td>1.141280e-11</td>\n",
       "      <td>1.613197e-07</td>\n",
       "      <td>3.154049e-08</td>\n",
       "      <td>8.637998e-08</td>\n",
       "      <td>6.435937e-09</td>\n",
       "      <td>1.281374e-06</td>\n",
       "      <td>1.792546e-07</td>\n",
       "      <td>1.011320e-08</td>\n",
       "      <td>1.451156e-09</td>\n",
       "      <td>8.100506e-10</td>\n",
       "      <td>...</td>\n",
       "      <td>2.571660e-10</td>\n",
       "      <td>7.685028e-11</td>\n",
       "      <td>1.454397e-10</td>\n",
       "      <td>1.087026e-09</td>\n",
       "      <td>3.969906e-10</td>\n",
       "      <td>1.039783e-09</td>\n",
       "      <td>2.806976e-11</td>\n",
       "      <td>1.082223e-10</td>\n",
       "      <td>1.151716e-11</td>\n",
       "      <td>1.452147e-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 99 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Acer_Capillipes  Acer_Circinatum     Acer_Mono   Acer_Opalus  \\\n",
       "id                                                                   \n",
       "1576     8.570116e-07     9.998349e-01  1.491306e-07  2.367666e-08   \n",
       "1577     2.488508e-07     9.220734e-08  1.271193e-09  1.042362e-06   \n",
       "1579     4.198415e-08     8.418455e-09  2.161047e-09  7.980462e-11   \n",
       "1580     3.757027e-10     1.785899e-10  9.808644e-09  5.898435e-09   \n",
       "1583     1.141280e-11     1.613197e-07  3.154049e-08  8.637998e-08   \n",
       "\n",
       "      Acer_Palmatum   Acer_Pictum  Acer_Platanoids   Acer_Rubrum  \\\n",
       "id                                                                 \n",
       "1576   8.240294e-05  7.842066e-08     3.390336e-09  1.839186e-06   \n",
       "1577   9.857609e-09  4.736718e-10     2.317026e-08  1.060710e-05   \n",
       "1579   9.189209e-08  2.276649e-07     7.560791e-11  1.875409e-08   \n",
       "1580   2.391792e-09  1.155581e-10     2.127765e-08  3.995165e-08   \n",
       "1583   6.435937e-09  1.281374e-06     1.792546e-07  1.011320e-08   \n",
       "\n",
       "      Acer_Rufinerve  Acer_Saccharinum       ...         Salix_Fragilis  \\\n",
       "id                                           ...                          \n",
       "1576    5.145595e-06      9.248885e-07       ...           3.526926e-08   \n",
       "1577    8.001536e-05      8.654126e-09       ...           1.390747e-08   \n",
       "1579    1.017468e-09      5.781226e-07       ...           7.700392e-13   \n",
       "1580    1.677714e-11      9.435058e-13       ...           2.021303e-08   \n",
       "1583    1.451156e-09      8.100506e-10       ...           2.571660e-10   \n",
       "\n",
       "      Salix_Intergra   Sorbus_Aria  Tilia_Oliveri  Tilia_Platyphyllos  \\\n",
       "id                                                                      \n",
       "1576    7.638954e-09  2.176534e-08   1.856065e-09        8.649973e-11   \n",
       "1577    6.374147e-09  4.393712e-06   8.712163e-10        1.003759e-05   \n",
       "1579    3.637695e-12  8.703355e-09   3.443338e-10        2.509468e-09   \n",
       "1580    1.709390e-07  4.398426e-12   8.780395e-08        2.148123e-13   \n",
       "1583    7.685028e-11  1.454397e-10   1.087026e-09        3.969906e-10   \n",
       "\n",
       "      Tilia_Tomentosa  Ulmus_Bergmanniana  Viburnum_Tinus  \\\n",
       "id                                                          \n",
       "1576     2.058003e-09        1.124400e-06    1.499914e-11   \n",
       "1577     1.025632e-05        1.602850e-07    2.873007e-11   \n",
       "1579     1.865638e-14        2.058288e-12    1.944001e-10   \n",
       "1580     7.722929e-09        4.900621e-11    2.568975e-10   \n",
       "1583     1.039783e-09        2.806976e-11    1.082223e-10   \n",
       "\n",
       "      Viburnum_x_Rhytidophylloides  Zelkova_Serrata  \n",
       "id                                                   \n",
       "1576                  2.453847e-09     2.271927e-05  \n",
       "1577                  2.523514e-09     2.382522e-05  \n",
       "1579                  2.157379e-09     1.884388e-07  \n",
       "1580                  5.571697e-13     1.249406e-10  \n",
       "1583                  1.151716e-11     1.452147e-07  \n",
       "\n",
       "[5 rows x 99 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "test = scaler.transform(test)\n",
    "test_pca=pca_fit.transform(test)\n",
    "test_predictions = gs_pca.predict_proba(test_pca)\n",
    "\n",
    "submission = pd.DataFrame(test_predictions, columns=classes)\n",
    "submission.insert(0, 'id', test_ids)\n",
    "submission.reset_index()\n",
    "submission.set_index('id', inplace=True)\n",
    "fp = open('submit.csv', 'w')\n",
    "fp.write(submission.to_csv())\n",
    "print('Finished writing submission')\n",
    "submission.tail()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
